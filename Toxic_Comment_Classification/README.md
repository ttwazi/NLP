# [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

This project developed a classification framework to classify natual language comments into the following six categories which are not mutually exclusive 1. toxic 2. severe_toxic 3. obscene 4. threat 5. insult 6.identity_hate. The comment is non-toxic if it can't be classified into any of the catefories.
